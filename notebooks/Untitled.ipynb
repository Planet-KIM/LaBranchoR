{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coated-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-spanking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sacred-forwarding",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 03:31:52.440060: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-16 03:31:52.850329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 22298 MB memory:  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 1633056768880663514\n",
       " xla_global_id: -1,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 23381475328\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 3435841969169439158\n",
       " physical_device_desc: \"device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
       " xla_global_id: 416903419]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "operating-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "auburn-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/home/dwkim/project/labranchor/')\n",
    "#from labranchor.create_fasta import Genome\n",
    "from genome import Genome\n",
    "genome = Genome('/home/dwkim/gencode_v19_raw_data/labranchor.gencode_v19.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "associate-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "introns = {}\n",
    "with open('/home/dwkim/anno/introns_to_mercer.tsv') as fp:\n",
    "    for line in fp:\n",
    "        chrom, start, end, _, pos, strand, _, bp = line.split('\\t')[:8]\n",
    "        bp, start, end = int(bp), int(start), int(end)\n",
    "        \n",
    "        three = end if strand == '+' else start  \n",
    "        key = (chrom, three, strand)\n",
    "        \n",
    "        if not 5 < abs(bp - three) < 60:\n",
    "            bp = -1\n",
    "        \n",
    "        if key not in introns: introns[key] = []\n",
    "        assert bp not in introns[key], bp\n",
    "        if bp != -1: introns[key] += [bp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cathedral-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2145\n"
     ]
    }
   ],
   "source": [
    "# Used to compare to branchpointer\n",
    "c = 0\n",
    "with open('./test.tsv', 'w') as fp:\n",
    "    ID = 0\n",
    "    fp.write('\\t'.join(['id', 'chromsome', 'start', 'end', 'strand']) + '\\n')\n",
    "    for (chrom, three, strand), bp in introns.items():\n",
    "        if not bp or chrom != 'chr1':\n",
    "            continue\n",
    "        if strand == '+':\n",
    "            begin, end = str(three - 70), str(three)\n",
    "        else:\n",
    "            c += 1\n",
    "            begin, end = str(three+1), str(three + 70+1)\n",
    "        \n",
    "        fp.write('\\t'.join([\"chr1_{}_{}\".format(three, strand),\n",
    "                            'chr1', begin, end, strand]) + '\\n')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "documented-copyright",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37110\n",
      "169182\n"
     ]
    }
   ],
   "source": [
    "known   = {key: value for key, value in introns.items() if value}\n",
    "missing = {key: value for key, value in introns.items() if not value}\n",
    "print(len(known))\n",
    "print(len(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dress-girlfriend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "(37110, 70, 4) (37110, 70) 37110\n"
     ]
    }
   ],
   "source": [
    "L = 70\n",
    "bases = ['A', 'C', 'G', 'T']\n",
    "\n",
    "def onehot(seq):\n",
    "    X = np.zeros((len(seq), len(bases)))\n",
    "    for i, char in enumerate(seq):\n",
    "        X[i, bases.index(char)] = 1\n",
    "    return X\n",
    "\n",
    "count =0 \n",
    "X, y, chroms = [], [], []\n",
    "for intron, bps in known.items():\n",
    "    count+=1\n",
    "    if count % 1000 == 0:\n",
    "        print(count)\n",
    "    chrom, three, strand = intron\n",
    "    if strand == '+':\n",
    "        begin, stop = three - L, three\n",
    "    else:\n",
    "        begin, stop = three, three + L\n",
    "    \n",
    "    # Get features\n",
    "    seq = genome.get_seq(chrom, begin, stop, strand)\n",
    "    #print(seq)\n",
    "    if 'N' in seq: seq = seq.replace('N', 'A')\n",
    "    \n",
    "    X += [onehot(seq).reshape(1, 70, 4)]\n",
    "\n",
    "    # Make target\n",
    "    _y = np.zeros((stop - begin,))\n",
    "    for bp in bps:\n",
    "        if strand == '+':\n",
    "            bp = L + bp - three\n",
    "        else:\n",
    "            bp = L - bp + three - 1\n",
    "        _y[bp] = 1\n",
    "    y += [_y]\n",
    "    \n",
    "    chroms += [chrom]\n",
    "\n",
    "X, y = np.vstack(X), np.vstack(y)\n",
    "print(X.shape, y.shape, len(chroms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "healthy-alexander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4306 7093 25711\n",
      "(25711, 70, 4) (7093, 70, 4) (4306, 70, 4)\n",
      "(25711, 70) (7093, 70) (4306, 70)\n"
     ]
    }
   ],
   "source": [
    "test = np.array(list(map(lambda x: x == 'chr1', chroms)))\n",
    "valid = np.array(list(map(lambda x: x in ('chr2', 'chr3', 'chr4', 'chr5'),\n",
    "                     chroms)))\n",
    "\n",
    "train = np.array([not (t or v) for t, v in zip(test, valid)])\n",
    "print(sum(test),  sum(valid), sum(train))\n",
    "\n",
    "X_train, X_valid, X_test = X[train], X[valid], X[test]\n",
    "y_train, y_valid, y_test = y[train], y[valid], y[test]\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "relevant-turtle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25711, 70, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.save('./X_train.npy', X_train)\n",
    "#np.save('./X_valid.npy', X_valid)\n",
    "#np.save('./X_test.npy', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "architectural-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(preds, true):\n",
    "    total, match = 0, 0\n",
    "    for p, t in zip(preds, true):\n",
    "        if np.argmax(p) in np.nonzero(t)[0]:\n",
    "            match += 1\n",
    "        total += 1\n",
    "    return match, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "quarterly-martin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8658.  8037.  8984. 20929.  9468.  9994.  9281.]\n",
      " [12046.  8055. 11683.  6820. 11738. 11016. 10508.]\n",
      " [ 8100.  7269.  8965.  5728.  8041.  7817.  8519.]\n",
      " [10247. 15690.  9419.  5574.  9804. 10224. 10743.]]\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "counts = np.zeros((2*K+1, 4))\n",
    "for target, seq in zip(y_train, X_train):\n",
    "    for bp in np.nonzero(target)[0]:\n",
    "        if 0 > bp-K or bp+K+1 > seq.shape[0]: continue\n",
    "        counts = counts + seq[bp-K: bp+K+1]\n",
    "print(counts.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "laden-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.train_auc = []\n",
    "        self.train_match = []\n",
    "        self.valid_auc = []\n",
    "        self.valid_match = []\n",
    "        \n",
    "    def train(self, X_train, X_valid,\n",
    "              y_train, y_valid, PATIENCE = 15, EPOCHS = 80):\n",
    "        print(model.summary())\n",
    "        for i in range(EPOCHS):\n",
    "            model.fit(X_train, y_train, epochs = 1, verbose = 0, batch_size = 8)\n",
    "            self._evaluate(X_train, X_valid, y_train, y_valid)\n",
    "            if (i > PATIENCE\n",
    "                and max(self.valid_match[-PATIENCE:])\n",
    "                < max(self.valid_match)):\n",
    "                break\n",
    "            print(i, self.valid_match[-1], self.train_match[-1])\n",
    "        self._plot_scores()\n",
    "        print(max(self.valid_match), max(self.valid_auc))\n",
    "        print('saved model')\n",
    "        model.save('./2layer_gpu.h5')\n",
    "    \n",
    "    def predict(X):\n",
    "        return self.model.predict(X)\n",
    "                \n",
    "    def _evaluate(self, X_train, X_valid, y_train, y_valid):\n",
    "        valid_preds = self.model.predict(X_valid, verbose=0)\n",
    "        train_preds = self.model.predict(X_train, verbose=0)\n",
    "        self.valid_match += [matching(valid_preds, y_valid)[0]\n",
    "                             / float(y_valid.shape[0])]\n",
    "        self.train_match += [matching(train_preds, y_train)[0]\n",
    "                             / float(y_train.shape[0])]\n",
    "        self.valid_auc += [metrics.roc_auc_score(y_valid.flatten(),\n",
    "                                                 valid_preds.flatten())]\n",
    "        self.train_auc += [metrics.roc_auc_score(y_train.flatten(),\n",
    "                                                 train_preds.flatten())]\n",
    "    \n",
    "    def _plot_scores(self):\n",
    "        plt.plot(self.valid_match, label = 'Validation')\n",
    "        plt.plot(self.train_match, label = 'Training')\n",
    "        plt.ylabel('Match')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(self.valid_auc, label = 'Validation')\n",
    "        plt.plot(self.train_auc, label = 'Training')\n",
    "        plt.ylabel('auROC')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "crazy-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, LSTM, Dropout, Reshape\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
    "from tensorflow.keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-market",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_8 (Bidirectio  (None, 70, 64)           9472      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 70, 64)           24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, 70, 1)            65        \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,369\n",
      "Trainable params: 34,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "0 0.3383617651205414 0.35082260511065305\n",
      "1 0.3545749330325673 0.36894714324608147\n",
      "2 0.35809953475257295 0.3756757807942126\n",
      "3 0.3703651487381926 0.38975535762903035\n",
      "4 0.3764274636966023 0.3971451907743767\n",
      "5 0.37783730438460456 0.39586169343860605\n",
      "6 0.40575215000704923 0.4264711602038038\n",
      "7 0.4019455801494431 0.42367080238030413\n",
      "8 0.4108275764838573 0.43012718291781726\n",
      "9 0.4229522064006767 0.44965189996499555\n",
      "10 0.41759481178626817 0.44440122904593365\n",
      "11 0.40265050049344425 0.4292326241686438\n",
      "12 0.45100803609192164 0.47438839407257594\n",
      "13 0.3875652051318201 0.40472949321302165\n",
      "14 0.47638516847596224 0.5071759169227179\n",
      "15 0.440011278725504 0.48306172455369295\n",
      "16 0.4308473142534894 0.4546303138734394\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True,\n",
    "                             dropout = 0.15, recurrent_dropout = 0.05),\n",
    "                            input_shape = (L, 4)))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True,\n",
    "                             dropout = 0.15, recurrent_dropout = 0.05)))\n",
    "\n",
    "model.add(TimeDistributed(Dense(1, activation = 'sigmoid')))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=0.001,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.999,\n",
    "                                        epsilon=1e-08,\n",
    "                                        decay=0.0))\n",
    "\n",
    "ModelTrainer(model).train(X_train[:, :, :4], X_valid[:, :, :4],\n",
    "                          y_train.reshape(-1, 70, 1), y_valid.reshape(-1, 70, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./2layer_gpu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-research",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-springfield",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
