{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "herbal-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, LSTM, Dropout, Reshape\n",
    "from tensorflow.keras.layers import Bidirectional, TimeDistributed\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "latin-huntington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25711, 70, 4) (7093, 70, 4) (4306, 70, 4)\n",
      "(25711, 70) (7093, 70) (4306, 70)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, X_test = np.load('./X_train.npy'), np.load('./X_valid.npy'), np.load('./X_test.npy')\n",
    "y_train, y_valid, y_test = np.load('./Y_train.npy'), np.load('./Y_valid.npy'), np.load('./Y_test.npy')\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(y_train.shape, y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "second-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching(preds, true):\n",
    "    total, match = 0, 0\n",
    "    for p, t in zip(preds, true):\n",
    "        if np.argmax(p) in np.nonzero(t)[0]:\n",
    "            match += 1\n",
    "        total += 1\n",
    "    return match, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "second-macintosh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8658.  8037.  8984. 20929.  9468.  9994.  9281.]\n",
      " [12046.  8055. 11683.  6820. 11738. 11016. 10508.]\n",
      " [ 8100.  7269.  8965.  5728.  8041.  7817.  8519.]\n",
      " [10247. 15690.  9419.  5574.  9804. 10224. 10743.]]\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "counts = np.zeros((2*K+1, 4))\n",
    "for target, seq in zip(y_train, X_train):\n",
    "    for bp in np.nonzero(target)[0]:\n",
    "        if 0 > bp-K or bp+K+1 > seq.shape[0]: continue\n",
    "        counts = counts + seq[bp-K: bp+K+1]\n",
    "print(counts.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quantitative-gregory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:16:44.821210: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-16 15:16:45.225836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 612 MB memory:  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 70, 64)           9472      \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 70, 64)           24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 70, 1)            65        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,369\n",
      "Trainable params: 34,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = load_model('./2layer.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alternative-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 15:18:08.980428: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:08.980489: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:08.984676: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:08.984692: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:08.988598: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:08.988613: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:08.992813: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:08.992831: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:08.997189: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:08.997207: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:09.002216: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:09.002239: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:09.006529: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:09.006546: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:09.010883: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:09.010899: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:09.015005: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:09.015020: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:09.019538: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:09.019558: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:09.023885: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:09.023901: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:09.028105: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:09.028121: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:09.032215: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:09.032232: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:09.036374: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:09.036390: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:09.040463: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:09.040478: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n",
      "2021-11-16 15:18:09.044526: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "2021-11-16 15:18:09.044541: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at matmul_op_impl.h:442 : INTERNAL: Attempting to perform BLAS operation using StreamExecutor without BLAS support\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[node sequential/bidirectional/forward_lstm/while/lstm_cell_1/MatMul\n (defined at /home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/backend.py:2134)\n]] [Op:__inference_test_function_2601]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential/bidirectional/forward_lstm/while/lstm_cell_1/MatMul:\nIn[0] sequential/bidirectional/forward_lstm/while/lstm_cell_1/mul (defined at /home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent.py:2455)\t\nIn[1] sequential/bidirectional/forward_lstm/while/lstm_cell_1/split (defined at /home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent.py:2464)\n\nOperation defined at: (most recent call last)\n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_122839/2481722733.py\", line 1, in <module>\n>>>     test_loss, test_acc = new_model.evaluate(X_train, y_train, verbose=2)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1537, in evaluate\n>>>     tmp_logs = self.test_function(iterator)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1366, in test_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1356, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1349, in run_step\n>>>     outputs = model.test_step(data)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1303, in test_step\n>>>     y_pred = self(x, training=False)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/wrappers.py\", line 586, in __call__\n>>>     return super(Bidirectional, self).__call__(inputs, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/wrappers.py\", line 701, in call\n>>>     y = self.forward_layer(forward_inputs,\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 679, in __call__\n>>>     return super(RNN, self).__call__(inputs, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent_v2.py\", line 1158, in call\n>>>     last_output, outputs, states = backend.rnn(\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/backend.py\", line 4654, in rnn\n>>>     final_outputs = tf.compat.v1.while_loop(\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/backend.py\", line 4640, in _step\n>>>     output, new_states = step_function(current_input,\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent_v2.py\", line 1156, in step\n>>>     return self.cell(inputs, states, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2466, in call\n>>>     x_i = backend.dot(inputs_i, k_i)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/backend.py\", line 2134, in dot\n>>>     out = tf.matmul(x, y)\n>>> \n\nFunction call stack:\ntest_function -> sequential_bidirectional_forward_lstm_while_body_1641\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_122839/2481722733.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gpu/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m:  Attempting to perform BLAS operation using StreamExecutor without BLAS support\n\t [[node sequential/bidirectional/forward_lstm/while/lstm_cell_1/MatMul\n (defined at /home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/backend.py:2134)\n]] [Op:__inference_test_function_2601]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sequential/bidirectional/forward_lstm/while/lstm_cell_1/MatMul:\nIn[0] sequential/bidirectional/forward_lstm/while/lstm_cell_1/mul (defined at /home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent.py:2455)\t\nIn[1] sequential/bidirectional/forward_lstm/while/lstm_cell_1/split (defined at /home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent.py:2464)\n\nOperation defined at: (most recent call last)\n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"/tmp/ipykernel_122839/2481722733.py\", line 1, in <module>\n>>>     test_loss, test_acc = new_model.evaluate(X_train, y_train, verbose=2)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1537, in evaluate\n>>>     tmp_logs = self.test_function(iterator)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1366, in test_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1356, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1349, in run_step\n>>>     outputs = model.test_step(data)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1303, in test_step\n>>>     y_pred = self(x, training=False)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/sequential.py\", line 373, in call\n>>>     return super(Sequential, self).call(inputs, training=training, mask=mask)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n>>>     return self._run_internal_graph(\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/wrappers.py\", line 586, in __call__\n>>>     return super(Bidirectional, self).__call__(inputs, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/wrappers.py\", line 701, in call\n>>>     y = self.forward_layer(forward_inputs,\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 679, in __call__\n>>>     return super(RNN, self).__call__(inputs, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent_v2.py\", line 1158, in call\n>>>     last_output, outputs, states = backend.rnn(\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/backend.py\", line 4654, in rnn\n>>>     final_outputs = tf.compat.v1.while_loop(\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/backend.py\", line 4640, in _step\n>>>     output, new_states = step_function(current_input,\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent_v2.py\", line 1156, in step\n>>>     return self.cell(inputs, states, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/layers/recurrent.py\", line 2466, in call\n>>>     x_i = backend.dot(inputs_i, k_i)\n>>> \n>>>   File \"/home/dwkim/.conda/envs/gpu/lib/python3.8/site-packages/keras/backend.py\", line 2134, in dot\n>>>     out = tf.matmul(x, y)\n>>> \n\nFunction call stack:\ntest_function -> sequential_bidirectional_forward_lstm_while_body_1641\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = new_model.evaluate(X_train, y_train, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-glasgow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python .conda-gpu",
   "language": "python",
   "name": "conda-env-.conda-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
